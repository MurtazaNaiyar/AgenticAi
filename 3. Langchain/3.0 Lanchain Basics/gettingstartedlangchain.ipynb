{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd7e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5892e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"LANGCHAIN_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47124a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000022E59C75D60> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022E59C75220> root_client=<openai.OpenAI object at 0x0000022E5945F8F0> root_async_client=<openai.AsyncOpenAI object at 0x0000022E59463AD0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed with agency, meaning they possess the capability to make decisions, take actions, and pursue goals autonomously or semi-autonomously. The concept draws inspiration from the notion of \"agency\" in philosophy and psychology, which involves the capacity of individuals (or entities) to act independently and make their own choices.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy**: Agentic AI can operate without constant human supervision, making decisions based on predefined objectives or learned behaviors.\\n   \\n2. **Goal-Oriented Behavior**: These AI systems are designed to achieve specific goals or outcomes. They can plan, prioritize tasks, and adjust strategies to meet their objectives effectively.\\n\\n3. **Adaptability and Learning**: Agentic AI often incorporates machine learning algorithms that enable it to learn from experiences, adapt to new information, and improve performance over time.\\n\\n4. **Decision-Making Capability**: Beyond following preset instructions, agentic AI can evaluate options, weigh consequences, and choose actions that align with its goals.\\n\\n5. **Environment Interaction**: These AI agents interact with their environment, whether physical or digital, to gather information, manipulate variables, and affect change to achieve desired outcomes.\\n\\n### Applications of Agentic AI\\n\\n- **Autonomous Vehicles**: Self-driving cars navigate roads, make real-time decisions, and adjust to changing traffic conditions without human intervention.\\n  \\n- **Robotics**: Service robots in healthcare or manufacturing settings perform tasks, adapt to new tasks, and interact with humans and other machines autonomously.\\n  \\n- **Personal Assistants**: Advanced virtual assistants can manage schedules, respond to queries, and perform tasks based on user preferences and behaviors.\\n  \\n- **Gaming AI**: Non-player characters (NPCs) with agency can exhibit complex behaviors, adapt to player actions, and enhance the gaming experience.\\n\\n### Ethical and Societal Considerations\\n\\nThe development and deployment of agentic AI raise several ethical and societal issues:\\n\\n- **Accountability**: Determining responsibility for actions taken by autonomous AI systems can be challenging.\\n  \\n- **Bias and Fairness**: Ensuring that AI agents make fair decisions without inherent biases present in their training data is crucial.\\n  \\n- **Job Displacement**: Automation of tasks through agentic AI may lead to changes in the job market, necessitating workforce adaptation.\\n  \\n- **Autonomy vs. Control**: Balancing the autonomy of AI agents with human oversight to prevent unintended consequences is a key concern.\\n\\n### Future of Agentic AI\\n\\nAs AI technologies advance, agentic AI is expected to become more sophisticated, with enhanced capabilities for understanding context, making nuanced decisions, and interacting seamlessly with humans. Ongoing research focuses on improving the reliability, safety, and ethical frameworks governing agentic AI to ensure beneficial outcomes for society.\\n\\n### Conclusion\\n\\nAgentic AI represents a significant evolution in artificial intelligence, enabling machines to act with a degree of independence and purpose. While offering numerous benefits across various sectors, it also necessitates careful consideration of the ethical, societal, and technical challenges associated with granting agency to AI systems.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 831, 'prompt_tokens': 13, 'total_tokens': 844, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BeRJCLnG5L8VhBuDY2XOjUgQLYacv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1c236cbd-ad31-4bb0-b7cd-08fe23f87fef-0' usage_metadata={'input_tokens': 13, 'output_tokens': 831, 'total_tokens': 844, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed with agency, meaning they possess the capability to make decisions, take actions, and pursue goals autonomously or semi-autonomously. The concept draws inspiration from the notion of \"agency\" in philosophy and psychology, which involves the capacity of individuals (or entities) to act independently and make their own choices.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI can operate without constant human supervision, making decisions based on predefined objectives or learned behaviors.\n",
      "   \n",
      "2. **Goal-Oriented Behavior**: These AI systems are designed to achieve specific goals or outcomes. They can plan, prioritize tasks, and adjust strategies to meet their objectives effectively.\n",
      "\n",
      "3. **Adaptability and Learning**: Agentic AI often incorporates machine learning algorithms that enable it to learn from experiences, adapt to new information, and improve performance over time.\n",
      "\n",
      "4. **Decision-Making Capability**: Beyond following preset instructions, agentic AI can evaluate options, weigh consequences, and choose actions that align with its goals.\n",
      "\n",
      "5. **Environment Interaction**: These AI agents interact with their environment, whether physical or digital, to gather information, manipulate variables, and affect change to achieve desired outcomes.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars navigate roads, make real-time decisions, and adjust to changing traffic conditions without human intervention.\n",
      "  \n",
      "- **Robotics**: Service robots in healthcare or manufacturing settings perform tasks, adapt to new tasks, and interact with humans and other machines autonomously.\n",
      "  \n",
      "- **Personal Assistants**: Advanced virtual assistants can manage schedules, respond to queries, and perform tasks based on user preferences and behaviors.\n",
      "  \n",
      "- **Gaming AI**: Non-player characters (NPCs) with agency can exhibit complex behaviors, adapt to player actions, and enhance the gaming experience.\n",
      "\n",
      "### Ethical and Societal Considerations\n",
      "\n",
      "The development and deployment of agentic AI raise several ethical and societal issues:\n",
      "\n",
      "- **Accountability**: Determining responsibility for actions taken by autonomous AI systems can be challenging.\n",
      "  \n",
      "- **Bias and Fairness**: Ensuring that AI agents make fair decisions without inherent biases present in their training data is crucial.\n",
      "  \n",
      "- **Job Displacement**: Automation of tasks through agentic AI may lead to changes in the job market, necessitating workforce adaptation.\n",
      "  \n",
      "- **Autonomy vs. Control**: Balancing the autonomy of AI agents with human oversight to prevent unintended consequences is a key concern.\n",
      "\n",
      "### Future of Agentic AI\n",
      "\n",
      "As AI technologies advance, agentic AI is expected to become more sophisticated, with enhanced capabilities for understanding context, making nuanced decisions, and interacting seamlessly with humans. Ongoing research focuses on improving the reliability, safety, and ethical frameworks governing agentic AI to ensure beneficial outcomes for society.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant evolution in artificial intelligence, enabling machines to act with a degree of independence and purpose. While offering numerous benefits across various sectors, it also necessitates careful consideration of the ethical, societal, and technical challenges associated with granting agency to AI systems.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"Hi My name is Krish.\" I should respond politely. Let me start with a friendly greeting. Maybe say hello back and ask how I can assist them. Keep it simple and open-ended so they feel comfortable to ask for help. Let me check for any typos. Yeah, that should work.\\n</think>\\n\\nHello Krish! Nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 15, 'total_tokens': 120, 'completion_time': 0.24636789, 'prompt_time': 0.004442553, 'queue_time': 0.35790094699999997, 'total_time': 0.250810443}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--27f55dc6-2a82-441c-a0a0-6b84727abee2-0', usage_metadata={'input_tokens': 15, 'output_tokens': 105, 'total_tokens': 120})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Krish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022E5A7E4650>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022E594EA8D0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022E5A7E4650>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022E594EA8D0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI Engineer, I can definitely tell you about LangSmith! \n",
      "\n",
      "LangSmith is an open-source platform developed by the Hugging Face team specifically designed for **building and fine-tuning large language models (LLMs)**. \n",
      "\n",
      "Here's a breakdown of its key features and benefits:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Simplified Fine-Tuning:** LangSmith streamlines the process of fine-tuning LLMs for specific tasks. It provides a user-friendly interface and pre-configured workflows, making it accessible even to users with limited machine learning expertise.\n",
      "* **Data Management:** It offers robust tools for managing and preprocessing training data, including text cleaning, formatting, and splitting.\n",
      "* **Experiment Tracking:**  LangSmith allows you to track your fine-tuning experiments, compare different model architectures and hyperparameters, and easily reproduce your results.\n",
      "* **Community Collaboration:** Being open-source, LangSmith benefits from a vibrant community of developers and researchers who contribute to its development, share their models and datasets, and provide support.\n",
      "* **Integration with Hugging Face Hub:** LangSmith seamlessly integrates with the Hugging Face Hub, enabling you to easily share your fine-tuned models with the wider community.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Accessibility:**  LangSmith democratizes access to LLM fine-tuning, enabling individuals and organizations of all sizes to leverage the power of these models.\n",
      "* **Efficiency:** Its streamlined workflows and pre-configured tools significantly reduce the time and effort required for fine-tuning.\n",
      "* **Transparency:**  The open-source nature of LangSmith promotes transparency and reproducibility in the LLM development process.\n",
      "* **Flexibility:** You can fine-tune a wide range of pre-trained LLMs from the Hugging Face Model Hub, tailoring them to your specific needs.\n",
      "\n",
      "**Overall, LangSmith is a powerful and user-friendly platform that empowers anyone to explore and harness the potential of large language models.**\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or anything else related to AI!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##  Let's Talk Langsmith: Your Open-Source Assistant for Building AI Apps\n",
      "\n",
      "Langsmith is a powerful, open-source platform designed to simplify the process of building and deploying AI applications, specifically those leveraging large language models (LLMs).  \n",
      "\n",
      "Think of it as a comprehensive toolkit for interacting with and customizing LLMs like GPT-3, making them readily accessible and adaptable to your specific needs. \n",
      "\n",
      "Here's a breakdown of what makes Langsmith stand out:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **No-code interface:**  Langsmith empowers users with little to no coding experience to build and experiment with AI applications.\n",
      "* **Modular design:** It allows you to easily combine different components like prompts, LLMs, and data sources to create complex workflows.\n",
      "* **Fine-tuning capabilities:**  You can customize pre-trained LLMs by fine-tuning them on your own data, leading to more accurate and relevant results for your specific use case.\n",
      "* **Version control:**  Track changes to your models and applications, ensuring reproducibility and easy rollback.\n",
      "* **Community-driven:**  Langsmith thrives on open collaboration, with a growing community of developers and users sharing resources and knowledge.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "* **Chatbots and conversational agents:**  Create interactive bots for customer service, education, or entertainment.\n",
      "* **Text generation:**  Generate creative content, summarize articles, write code, or translate languages.\n",
      "* **Data analysis and insights:**  Extract key information from unstructured text data, identify patterns, and generate reports.\n",
      "* **Personal productivity tools:**  Automate tasks like scheduling appointments, drafting emails, or summarizing meeting notes.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Accessibility:**  Democratizes access to powerful LLMs, enabling individuals and organizations of all sizes to leverage AI.\n",
      "* **Flexibility:**  Offers a wide range of customization options to tailor models to specific needs.\n",
      "* **Efficiency:**  Streamlines the development process, allowing you to focus on building innovative applications rather than infrastructure.\n",
      "* **Cost-effectiveness:**  Leverages open-source tools and resources, reducing development costs.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "* Visit the Langsmith website ([https://www.langsmith.com/](https://www.langsmith.com/)) for documentation, tutorials, and community forums.\n",
      "* Explore the open-source code repository on GitHub ([https://github.com/langsmith-ai/langsmith](https://github.com/langsmith-ai/langsmith)).\n",
      "\n",
      "\n",
      "Langsmith is a powerful platform that empowers anyone to explore and build with LLMs. Its open-source nature, user-friendly interface, and extensive features make it a valuable tool for individuals, researchers, and businesses looking to harness the potential of AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for building and deploying AI assistants.', 'features': ['Modular design allows for easy customization and extension.', 'Supports multiple language models, including GPT-3 and Llama.', 'Provides tools for fine-tuning and evaluating models.', 'Offers a user-friendly interface for creating and managing AI assistants.', 'Built on top of existing infrastructure like LangChain and LlamaIndex.'], 'website': 'https://www.langsmith.com/', 'github': 'https://github.com/langsmithai'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source framework designed to simplify the development and deployment of language models. It provides a set of tools and functionalities that streamline the entire process, from training to fine-tuning and serving. \\n\\nHere are some key aspects of Langsmith:\\n\\n* **Modular Design:** Langsmith is built with a modular architecture, allowing developers to easily integrate different components and customize their workflows.\\n\\n* **Training and Fine-tuning:** It offers robust tools for training and fine-tuning language models, supporting various architectures and datasets.\\n\\n* **Model Serving:** Langsmith enables efficient serving of trained models through APIs, allowing for seamless integration into applications.\\n\\n* **Community-driven:** As an open-source project, Langsmith benefits from a vibrant community of developers who contribute to its development and provide support.\\n\\n* **Ease of Use:**  Langsmith aims to make working with language models more accessible by providing a user-friendly interface and intuitive APIs.'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response>\\n  <model>Langsmith</model>\\n  <description>Langsmith is an open-source platform for building and deploying AI applications. It provides a framework for developing, training, and evaluating language models, as well as tools for deploying them in production.</description>\\n  <features>\\n    <feature>Modular design</feature>\\n    <feature>Support for multiple programming languages</feature>\\n    <feature>Easy integration with existing tools</feature>\\n    <feature>Open-source and community-driven</feature>\\n  </features>\\n  <website>https://www.langsmith.ai/</website>\\n</response> \\n\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 195, 'total_tokens': 339, 'completion_time': 0.261818182, 'prompt_time': 0.009446571, 'queue_time': 0.246504287, 'total_time': 0.271264753}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0bde4c43-4268-4beb-b4c4-aa3a32f86747-0' usage_metadata={'input_tokens': 195, 'output_tokens': 144, 'total_tokens': 339}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools and components to streamline the process of integrating LLMs into various applications, such as chatbots, question-answering systems, and text summarizers. </answer></response>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 39, 'total_tokens': 108, 'completion_time': 0.125454545, 'prompt_time': 0.003350234, 'queue_time': 0.243215077, 'total_time': 0.128804779}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0d9d3374-01e5-4474-b3a2-e9963c5226b6-0' usage_metadata={'input_tokens': 39, 'output_tokens': 69, 'total_tokens': 108}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why did the scarecrow win an award? Because he was outstanding in his field!'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>Philadelphia</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Sully</movie>\n",
      "<movie>Toy Story</movie>\n",
      "<movie>Sleepless in Seattle</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
